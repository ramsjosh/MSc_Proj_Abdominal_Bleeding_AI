{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzUgBhfihCrLIjF9jecXIw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**2.5D Stack Dataset Loader (with Optional Segmentation Masks)**\n","\n","This `Dataset` class loads 2.5D CT stacks for classification (and, if available, segmentation):\n","- Loads each stack as a `[C, H, W]` tensor (C = stack size × 3).\n","- Optionally loads and returns a matching segmentation mask stack.\n","- Applies Albumentations transforms to both image and mask.\n","- Returns: (image stack, label, mask stack/dummy).\n"],"metadata":{"id":"v8WxoJ26dZzv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fswD6pQ1dYBW"},"outputs":[],"source":["class Stack2p5DDataset(Dataset):\n","    \"\"\"\n","    Loads 2.5D stacks of CT slices with optional segmentation masks.\n","    \"\"\"\n","    def __init__(self, index_csv, npy_dir, mask_dir, transform=None):\n","        self.df = pd.read_csv(index_csv)\n","        self.npy_dir = npy_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        stack_files = eval(row['stack_npy_files'])  # List of .npy files for the stack\n","\n","        # Load stack of 3-channel CT slices\n","        stack = [np.load(os.path.join(self.npy_dir, fname)) for fname in stack_files]  # Each: [3, H, W]\n","        stack = np.stack(stack, axis=0)                # [stack_size, 3, H, W]\n","        stack = stack.reshape(-1, stack.shape[2], stack.shape[3])  # [C, H, W], C = stack_size * 3\n","\n","        # For augmentation: [H, W, C]\n","        stack_img = np.transpose(stack, (1, 2, 0))\n","\n","        # Load segmentation mask if available\n","        mask_tensor = None\n","        if row['has_mask']:\n","            series_id = str(row['series_id'])\n","            mask_path = os.path.join(self.mask_dir, f\"{series_id}.nii\")\n","            mask_data = nib.load(mask_path).get_fdata()  # [H, W, num_slices]\n","            slice_indices = eval(row['stack_slice_ids'])\n","            mask_slices = [mask_data[:, :, idx] for idx in slice_indices]\n","            mask_stack = np.stack(mask_slices, axis=-1).astype(np.float32)  # [H, W, stack_size]\n","            # Albumentations expects [H, W, stack_size]\n","        else:\n","            mask_stack = None\n","\n","        # Apply augmentation\n","        if self.transform:\n","            if mask_stack is not None:\n","                augmented = self.transform(image=stack_img, mask=mask_stack)\n","                stack_img = augmented['image']\n","                mask_stack = augmented['mask']\n","            else:\n","                stack_img = self.transform(image=stack_img)['image']\n","\n","        # Convert image to [C, H, W] for PyTorch\n","        stack = np.transpose(stack_img, (2, 0, 1))\n","        label = int(row['label'])\n","\n","        # Convert mask to tensor\n","        if mask_stack is not None:\n","            mask_tensor = torch.tensor(np.transpose(mask_stack, (2, 0, 1)), dtype=torch.float32)\n","\n","        return torch.tensor(stack, dtype=torch.float32), torch.tensor(label, dtype=torch.long), mask_tensor"]},{"cell_type":"markdown","source":["**2.5D ResNet18 Feature Extractor**\n","\n","- **IMAGENET1K_V1** refers to the official ResNet-18 pretrained weights provided by torchvision (PyTorch's computer vision library).\n","- These weights are trained on the large-scale [ImageNet-1k dataset](https://www.image-net.org/), which contains 1,000 classes and over a million natural images.\n","- Using `weights=\"IMAGENET1K_V1\"` is the modern way (torchvision ≥ 0.13) to enable pretrained models for transfer learning in PyTorch.\n","\n","**References:**\n","- [torchvision.models.resnet18 Documentation](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html)\n","- [ImageNet-1k Dataset](https://www.image-net.org/)\n","- [Torchvision Model Weights Reference](https://pytorch.org/vision/stable/models.html#torchvision.models.ResNet18_Weights)\n"],"metadata":{"id":"1EjD3LCNdchN"}},{"cell_type":"code","source":["def build_2p5d_resnet18(in_channels=3, pretrained=False):\n","    \"\"\"\n","    Creates a modified ResNet-18 backbone for 2.5D stacks.\n","\n","    \"\"\"\n","    # For torchvision >=0.13, use 'weights' arg for pretrained model.\n","    # 'IMAGENET1K_V1' means weights from training on the ImageNet-1k dataset.\n","    model = models.resnet18(weights=\"IMAGENET1K_V1\" if pretrained else None)\n","\n","    # Replace first conv layer to accept in_channels (e.g. 9 for 2.5D, not just 3)\n","    model.conv1 = nn.Conv2d(\n","        in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n","    )\n","\n","    # Remove average pooling and first conv layers; keep only convolutional backbone\n","    modules = list(model.children())[:-2]\n","    backbone = nn.Sequential(*modules)\n","    return backbone"],"metadata":{"id":"J078ewObdeKn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**CNN+RNN Multi-Task Model for 2.5D CT Bleeding Detection**\n","\n","This module defines a **multi-task deep learning model** for trauma CT analysis:\n","- **Input:** 2.5D stacks of multi-channel CT images ([B, T, C, H, W])\n","- **Backbone:** Modified ResNet-18 CNN for feature extraction\n","- **RNN:** LSTM aggregates stack-level features for patient-level classification\n","- **Segmentation Head:** Outputs per-slice (stack) segmentation masks (upsampled to original resolution)\n","- **Outputs:**\n","    - Patient-level bleeding classification logits `[B, num_classes]`\n","    - Stack-level segmentation mask logits `[B, T, H, W]`\n","\n","Main Architecture Flow:\n","1. Each 2.5D stack is encoded using the CNN backbone.\n","2. The sequence of stack features is aggregated via a bidirectional LSTM.\n","3. The classification head predicts if the patient has bleeding.\n","4. The segmentation head predicts a binary mask for each stack (slice) in the sequence, resized to the input size.\n","\n","**Key implementation features:**\n","- Uses `F.interpolate` to upsample segmentation mask logits to match input dimensions.\n","- Flexible and ready for multi-task learning with PyTorch."],"metadata":{"id":"GPhsi-HadfaO"}},{"cell_type":"code","source":["class CNN_RNN_PatientClassifier_MTL(nn.Module):\n","    \"\"\"\n","    Multi-task model:\n","      - CNN (ResNet18) extracts features from each stack.\n","      - LSTM aggregates features across stacks (for each patient).\n","      - Classifier predicts bleeding (patient-level).\n","      - Segmentation head predicts per-stack masks.\n","    \"\"\"\n","    def __init__(self, in_channels=3, cnn_feature_dim=512, rnn_hidden=128, num_classes=2, rnn_layers=1, bidirectional=True):\n","        super().__init__()\n","        self.cnn = build_2p5d_resnet18(in_channels=in_channels)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.rnn = nn.LSTM(\n","            input_size=cnn_feature_dim,\n","            hidden_size=rnn_hidden,\n","            num_layers=rnn_layers,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","        rnn_output_dim = rnn_hidden * (2 if bidirectional else 1)\n","        self.classifier = nn.Linear(rnn_output_dim, num_classes)\n","        self.seg_head = nn.Conv2d(cnn_feature_dim, 1, kernel_size=1)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: [B, T, C, H, W] - B: batch (patients), T: stacks per patient\n","        Returns:\n","            out: [B, num_classes] - patient-level logits\n","            seg_logits: [B, T, H, W] - segmentation logits for each stack\n","        \"\"\"\n","        B, T, C, H, W = x.shape\n","        x_cnn = x.view(B * T, C, H, W)                        # [B*T, C, H, W]\n","        feats = self.cnn(x_cnn)                               # [B*T, cnn_feature_dim, h', w']\n","\n","        # Segmentation prediction for each stack\n","        seg_logits_small = self.seg_head(feats)               # [B*T, 1, h', w']\n","        seg_logits = F.interpolate(seg_logits_small, size=(H, W), mode='bilinear', align_corners=False)  # [B*T, 1, H, W]\n","\n","        # Feature aggregation for classification\n","        feats_gap = self.gap(feats).view(B * T, -1)           # [B*T, cnn_feature_dim]\n","        feats_rnn_input = feats_gap.view(B, T, -1)            # [B, T, cnn_feature_dim]\n","        rnn_out, _ = self.rnn(feats_rnn_input)                # [B, T, rnn_hidden*(2)]\n","        aggregated = torch.mean(rnn_out, dim=1)               # [B, rnn_hidden*(2)]\n","        out = self.classifier(aggregated)                     # [B, num_classes]\n","\n","        seg_logits = seg_logits.view(B, T, 1, H, W).squeeze(2)\n","        return out, seg_logits"],"metadata":{"id":"eFoHbAqediC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**PatientStackDataset: Loads All Stacks for a Patient**\n","\n","It loads all 2.5D stacks for a patient, including associated segmentation masks, and applies augmentation. Returns tensors ready for model input."],"metadata":{"id":"-eEiKffpdkDl"}},{"cell_type":"code","source":["# import ast\n","\n","class PatientStackDataset(Dataset):\n","    \"\"\"\n","    Loads all 2.5D stacks for a patient with optional segmentation masks.\n","    Returns tensors: (stacks, labels, masks)\n","    \"\"\"\n","    def __init__(self, df, patient_ids, npy_dir, mask_dir, transform=None):\n","        # Ensure patient_id is the index for efficient lookup\n","        if 'patient_id' in df.columns:\n","            df = df.set_index('patient_id')\n","        self.df = df\n","        self.patient_ids = patient_ids\n","        self.npy_dir = npy_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.patient_ids)\n","\n","    def __getitem__(self, idx):\n","        patient_id = self.patient_ids[idx]\n","\n","        # Use .loc for safe indexing and handle single-row cases\n","        patient_df_slice = self.df.loc[[patient_id]]\n","        patient_df = patient_df_slice.sort_values(by='center_slice')\n","\n","        stacks, labels, masks = [], [], []\n","\n","        for _, row in patient_df.iterrows():\n","            try:\n","                # Safely evaluate the string representation of the list\n","                stack_filename = ast.literal_eval(row['stack_npy_files'])[0]\n","            except (ValueError, SyntaxError):\n","                continue # Skip if the entry is malformed\n","\n","            npy_path = os.path.join(self.npy_dir, stack_filename)\n","            if not os.path.exists(npy_path):\n","                continue\n","\n","            stack = np.load(npy_path)\n","            if stack.shape[0] == 3:\n","                stack = np.transpose(stack, (1, 2, 0))  # (H, W, C) for augmentation\n","\n","            # Correctly load the mask based on the 'has_mask' flag\n","            mask = np.zeros((stack.shape[0], stack.shape[1], 1), dtype=np.float32)\n","            if row['has_mask']:\n","                # Construct the correct path using ONLY the series_id\n","                mask_series_path = os.path.join(self.mask_dir, f\"{int(row['series_id'])}.npy\")\n","\n","                if os.path.exists(mask_series_path):\n","                    try:\n","                        # Load the full 3D mask volume and get the correct slice\n","                        full_mask_volume = np.load(mask_series_path)\n","                        center_slice_idx = int(row['center_slice'])\n","\n","                        # Check bounds to prevent errors\n","                        if 0 <= center_slice_idx < full_mask_volume.shape[0]:\n","                            mask_slice = full_mask_volume[center_slice_idx]\n","                            if mask_slice.ndim == 2:\n","                                mask = np.expand_dims(mask_slice, axis=-1)\n","                            else:\n","                                mask = mask_slice # Already has channel dim\n","                    except Exception as e:\n","                        # If loading fails for any reason, default to a zero mask\n","                        print(f\"Warning: Could not load mask slice for {row['series_id']}/{row['center_slice']}. Error: {e}\")\n","                        pass # mask remains zeros\n","\n","            if self.transform:\n","                augmented = self.transform(image=stack, mask=mask)\n","                stack = augmented['image']\n","                mask = augmented['mask']\n","\n","            # Transpose to PyTorch format (C, H, W)\n","            stack = np.transpose(stack, (2, 0, 1))\n","            mask = np.transpose(mask, (2, 0, 1))\n","\n","            stacks.append(stack)\n","            labels.append(row['label'])\n","            masks.append(mask)\n","\n","        if not stacks:\n","            return torch.tensor([]), torch.tensor([]), torch.tensor([])\n","\n","        stacks_tensor = torch.tensor(np.array(stacks), dtype=torch.float32)\n","        labels_tensor = torch.tensor(np.array(labels), dtype=torch.float32)\n","        masks_tensor = torch.tensor(np.array(masks), dtype=torch.float32)\n","\n","        return stacks_tensor, labels_tensor, masks_tensor"],"metadata":{"id":"lGuhAKHJdlnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dataset Initialization and Model Setup**\n","\n","Defines file paths, prepares train/val/test datasets, and initializes the multi-task model.\n"],"metadata":{"id":"OCUMMPULdnTl"}},{"cell_type":"code","source":["# Data folder paths\n","npy_dir = '/content/drive/MyDrive/MSc_project/preproc_npy_3ch'\n","mask_dir = '/content/segmentations'\n","\n","# Create patient-level datasets (with and without augmentation)\n","train_patient_dataset = PatientStackDataset(df, train_patient_ids, npy_dir, mask_dir, transform=train_transform)\n","val_patient_dataset   = PatientStackDataset(df, val_patient_ids, npy_dir, mask_dir, transform=None)\n","test_patient_dataset  = PatientStackDataset(df, test_patient_ids, npy_dir, mask_dir, transform=None)\n","\n","print(f\"Train patient dataset: {len(train_patient_dataset)} patients\")\n","print(f\"Validation patient dataset: {len(val_patient_dataset)} patients\")\n","print(f\"Test patient dataset: {len(test_patient_dataset)} patients\")\n","\n","# Set computation device and initialize the multi-task model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = CNN_RNN_PatientClassifier_MTL(in_channels=3).to(device)"],"metadata":{"id":"hUfen9A5dpp4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Custom Collate Function for Patient-Level Batching**\n","\n","This function pads each patient's sequence of stacks and masks to the same length for batching.\n"],"metadata":{"id":"cvtkfEa-drcg"}},{"cell_type":"code","source":["# from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_fn_padd_with_mask(batch):\n","    # Remove empty data points\n","    batch = [item for item in batch if item[0].nelement() > 0]\n","    if not batch:\n","        return torch.tensor([]), torch.tensor([]), torch.tensor([]), torch.tensor([])\n","\n","    # Split batch into images, labels, masks\n","    batch_x   = [item[0] for item in batch]\n","    batch_y   = [item[1] for item in batch]\n","    batch_mask = [item[2] for item in batch]\n","\n","    # Sequence lengths for each patient\n","    lengths = torch.tensor([len(item) for item in batch_x])\n","\n","    # Pad sequences for batching:\n","    padded_batch_x = pad_sequence(batch_x, batch_first=True, padding_value=0)\n","    padded_batch_y = pad_sequence(batch_y, batch_first=True, padding_value=0)\n","    padded_batch_mask = pad_sequence(batch_mask, batch_first=True, padding_value=0)\n","\n","    return padded_batch_x, padded_batch_y, padded_batch_mask, lengths"],"metadata":{"id":"BzksKPhDdtq-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**DataLoader Instantiation**\n","\n","Creates DataLoaders for training, validation, and testing, using the custom collate function for padded patient sequences."],"metadata":{"id":"FYwUNFyIdw4d"}},{"cell_type":"code","source":["# Instantiate Dataloader\n","train_loader = DataLoader(\n","    train_patient_dataset, batch_size=2, shuffle=True, num_workers=0,\n","    collate_fn=collate_fn_padd_with_mask, pin_memory=True\n",")\n","val_loader = DataLoader(\n","    val_patient_dataset, batch_size=2, shuffle=False, num_workers=0,\n","    collate_fn=collate_fn_padd_with_mask, pin_memory=True\n",")\n","test_loader = DataLoader(\n","    test_patient_dataset, batch_size=2, shuffle=False, num_workers=0,\n","    collate_fn=collate_fn_padd_with_mask, pin_memory=True\n",")"],"metadata":{"id":"92BtcgiCdxVA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**DataLoader Shape Check**\n","\n","Checks the output shapes from the DataLoader to ensure batching and padding are correct."],"metadata":{"id":"yfQg67CidzY9"}},{"cell_type":"code","source":["print(\"Checking the output shape of the train_loader...\")\n","\n","for batch_x, batch_y, batch_mask, lengths in train_loader:\n","    print(\"\\nSuccessfully loaded one batch!\")\n","    print('  - Images Batch Shape  (B, S_max, C, H, W):', batch_x.shape)\n","    print('  - Labels Batch Shape  (B, S_max):', batch_y.shape)\n","    print('  - Masks Batch Shape   (B, S_max, 1, H, W):', batch_mask.shape)\n","    print('  - Lengths Batch Shape (B):', lengths.shape)\n","    print('  - Original sequence lengths in this batch:', lengths.tolist())\n","    break\n","\n","print(\"\\nShape check complete. The DataLoader is working correctly.\")"],"metadata":{"id":"hj8ETLqVd3H9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**EarlyStopping Utility**\n","\n","Implements early stopping to halt training when validation performance stops improving, and saves the best model weights.\n"],"metadata":{"id":"A0M71qrMeGfk"}},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=7, mode='max'):\n","        self.patience = patience\n","        self.mode = mode\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.best_model_wts = None\n","\n","    def __call__(self, score, model):\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.best_model_wts = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n","        elif (self.mode == 'max' and score > self.best_score) or (self.mode == 'min' and score < self.best_score):\n","            self.best_score = score\n","            self.counter = 0\n","            self.best_model_wts = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True"],"metadata":{"id":"Li4P6Ch9eG1W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Metric Computation Utility**\n","\n","Calculates accuracy, sensitivity, specificity, and AUC for model evaluation."],"metadata":{"id":"9yW-p98ZeIRc"}},{"cell_type":"code","source":["# from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n","\n","def compute_metrics(y_true, y_pred, y_prob):\n","    \"\"\"\n","    Computes standard classification metrics given true and predicted labels/probabilities.\n","    Returns:\n","        acc:         Accuracy\n","        sensitivity: Recall for positives (TPR)\n","        specificity: Recall for negatives (TNR)\n","        AUC:         Area under the ROC curve\n","    \"\"\"\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n","\n","    acc = accuracy_score(y_true, y_pred)\n","    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n","\n","    #Add a check\n","    try:\n","        auc = roc_auc_score(y_true, y_prob)\n","    except ValueError:\n","        auc = 0.5\n","\n","    return acc, sensitivity, specificity, auc"],"metadata":{"id":"2UU0WicxeJgV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Segmentation Loss Functions**\n","\n","Defines the loss functions for segmentation: Binary Cross Entropy (BCE), Dice loss, and a weighted combination of both."],"metadata":{"id":"2zY-FkLCeLac"}},{"cell_type":"code","source":["# Binary Cross Entropy loss with logits (for segmentation masks)\n","bce_loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n","\n","def dice_loss(pred, target, eps=1e-6):\n","    \"\"\"\n","    Computes Dice loss for segmentation.\n","    \"\"\"\n","    pred = torch.sigmoid(pred)\n","    target = target.float()\n","    pred = pred.contiguous().view(pred.size(0), -1)\n","    target = target.contiguous().view(target.size(0), -1)\n","    intersection = (pred * target).sum(dim=1)\n","    union = pred.sum(dim=1) + target.sum(dim=1)\n","    dice = (2. * intersection + eps) / (union + eps)\n","    return 1 - dice.mean()\n","\n","def combo_loss(pred, target, bce_weight=0.5, dice_weight=0.5):\n","    \"\"\"\n","    Weighted sum of BCE and Dice loss for segmentation.\n","    \"\"\"\n","    bce = bce_loss_fn(pred, target)\n","    dice = dice_loss(pred, target)\n","    return bce_weight * bce + dice_weight * dice"],"metadata":{"id":"ZPKow7PieOx2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Loss Functions for Training**\n","\n","Defines the loss functions for both segmentation and classification tasks."],"metadata":{"id":"MWoAftNZePQ1"}},{"cell_type":"code","source":["# Segmentation loss: Binary Cross-Entropy with logits (for organ mask prediction)\n","seg_criterion = nn.BCEWithLogitsLoss(reduction='mean')\n","\n","# Classification loss: Cross-Entropy (for patient-level bleeding detection)\n","cls_criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"ccMJ0bR0eRAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Function for One Epoch**\n","\n","Trains the model for one epoch, handling both classification and segmentation, and computes metrics."],"metadata":{"id":"Ha8x6mgPeaqT"}},{"cell_type":"code","source":["def train_one_epoch(model, loader, cls_criterion, seg_criterion, optimizer, device, epoch, num_epochs, seg_weight=1.0):\n","    model.train()\n","    losses, seg_losses, cls_losses = [], [], []\n","    all_y, all_logits = [], []\n","\n","    progress = tqdm(loader, desc=f\"Epoch {epoch+1} [Train Patient]\", leave=False)\n","    for batch_x, batch_y, batch_mask, lengths in progress:\n","        batch_x = batch_x.to(device)\n","        batch_y = batch_y.to(device)\n","        batch_mask = batch_mask.to(device)\n","\n","        logits, seg_logits = model(batch_x)\n","\n","        # True patient label: max label across the sequence (any stack with bleeding = patient positive)\n","        true_patient_labels = torch.max(batch_y, dim=1).values.long()\n","        cls_loss = cls_criterion(logits, true_patient_labels)\n","        cls_losses.append(cls_loss.item())\n","\n","        # Segmentation loss: only for stacks with non-empty masks\n","        seg_loss = torch.tensor(0.0, device=device)\n","        n_segs = 0\n","        for b in range(batch_x.shape[0]):\n","            true_length = lengths[b]\n","            for t in range(true_length):\n","                target_mask = batch_mask[b, t]\n","                pred_mask = seg_logits[b, t]\n","                if target_mask.max() > 0:\n","                    seg_loss += combo_loss(pred_mask, target_mask)\n","                    n_segs += 1\n","        if n_segs > 0:\n","            seg_loss = seg_loss / n_segs\n","        seg_losses.append(seg_loss.item())\n","\n","        total_loss = cls_loss + seg_weight * seg_loss\n","        optimizer.zero_grad()\n","        total_loss.backward()\n","        optimizer.step()\n","        losses.append(total_loss.item())\n","\n","        all_y.append(true_patient_labels.cpu().numpy())\n","        all_logits.append(torch.softmax(logits, 1)[:, 1].detach().cpu().numpy())\n","        progress.set_postfix({\"loss\": f\"{total_loss.item():.4f}\", \"cls\": f\"{cls_loss.item():.4f}\", \"seg\": f\"{seg_loss.item():.4f}\"})\n","\n","    all_y = np.concatenate(all_y)\n","    all_probs = np.concatenate(all_logits)\n","    all_pred = (all_probs >= 0.5).astype(int)\n","    acc, sens, spec, auc = compute_metrics(all_y, all_pred, all_probs)\n","    return np.mean(losses), np.mean(cls_losses), np.mean(seg_losses), acc, sens, spec, auc"],"metadata":{"id":"y_cYhUqHea9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Validation Function**\n","\n","Evaluates the model on the validation set"],"metadata":{"id":"rCenQ-1IecdU"}},{"cell_type":"code","source":["@torch.no_grad()\n","def validate(model, loader, cls_criterion, seg_criterion, device, epoch, num_epochs, seg_weight=1.0):\n","    model.eval()\n","    losses, seg_losses, cls_losses = [], [], []\n","    all_y, all_logits = [], []\n","\n","    progress = tqdm(loader, desc=f\"Epoch {epoch+1} [Val Patient]\", leave=False)\n","    for batch_x, batch_y, batch_mask, lengths in progress:\n","        batch_x = batch_x.to(device)\n","        batch_y = batch_y.to(device)\n","        batch_mask = batch_mask.to(device)\n","\n","        logits, seg_logits = model(batch_x)\n","\n","        # True patient label from max across sequence\n","        true_patient_labels = torch.max(batch_y, dim=1).values.long()\n","        cls_loss = cls_criterion(logits, true_patient_labels)\n","        cls_losses.append(cls_loss.item())\n","\n","        # Segmentation loss\n","        seg_loss = torch.tensor(0.0, device=device)\n","        n_segs = 0\n","        for b in range(batch_x.shape[0]):\n","            true_length = lengths[b]\n","            for t in range(true_length):\n","                target_mask = batch_mask[b, t]\n","                pred_mask = seg_logits[b, t]\n","                if target_mask.max() > 0:\n","                    seg_loss += combo_loss(pred_mask, target_mask)\n","                    n_segs += 1\n","        if n_segs > 0:\n","            seg_loss = seg_loss / n_segs\n","        seg_losses.append(seg_loss.item())\n","\n","        total_loss = cls_loss + seg_weight * seg_loss\n","        losses.append(total_loss.item())\n","\n","        all_y.append(true_patient_labels.cpu().numpy())\n","        all_logits.append(torch.softmax(logits, 1)[:, 1].detach().cpu().numpy())\n","        progress.set_postfix({\"loss\": f\"{total_loss.item():.4f}\", \"cls\": f\"{cls_loss.item():.4f}\", \"seg\": f\"{seg_loss.item():.4f}\"})\n","\n","    all_y = np.concatenate(all_y)\n","    all_probs = np.concatenate(all_logits)\n","    all_pred = (all_probs >= 0.5).astype(int)\n","    acc, sens, spec, auc = compute_metrics(all_y, all_pred, all_probs)\n","    return np.mean(losses), np.mean(cls_losses), np.mean(seg_losses), acc, sens, spec, auc"],"metadata":{"id":"IBcmy1l2edtk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training Loop**\n","\n","Main training loop for the multi-task model, including early stopping, logging, and history saving."],"metadata":{"id":"9ptkJtWIeglt"}},{"cell_type":"code","source":["def run_training(\n","    model, train_loader, val_loader, device, num_epochs=30, lr=1e-4,\n","    seg_weight=1.0, patience=7, ckpt_path=None, hist_path=None\n","):\n","    \"\"\"\n","    Main training loop for the multi-task model (classification + segmentation).\n","    Tracks training/validation losses and metrics, applies early stopping, and saves history for plotting.\n","    \"\"\"\n","    model = model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    early_stopper = EarlyStopping(patience=patience, mode='max')\n","\n","    history = {\n","        'train_loss': [], 'train_cls_loss': [], 'train_seg_loss': [], 'train_acc': [], 'train_auc': [],\n","        'val_loss': [], 'val_cls_loss': [], 'val_seg_loss': [], 'val_acc': [], 'val_auc': []\n","    }\n","\n","    for epoch in range(num_epochs):\n","        train_loss, train_cls_loss, train_seg_loss, train_acc, train_sens, train_spec, train_auc = train_one_epoch(\n","            model, train_loader, cls_criterion, seg_criterion, optimizer, device, epoch, num_epochs, seg_weight)\n","        val_loss, val_cls_loss, val_seg_loss, val_acc, val_sens, val_spec, val_auc = validate(\n","            model, val_loader, cls_criterion, seg_criterion, device, epoch, num_epochs, seg_weight)\n","\n","        history['train_loss'].append(train_loss)\n","        history['train_cls_loss'].append(train_cls_loss)\n","        history['train_seg_loss'].append(train_seg_loss)\n","        history['train_acc'].append(train_acc)\n","        history['train_auc'].append(train_auc)\n","        history['val_loss'].append(val_loss)\n","        history['val_cls_loss'].append(val_cls_loss)\n","        history['val_seg_loss'].append(val_seg_loss)\n","        history['val_acc'].append(val_acc)\n","        history['val_auc'].append(val_auc)\n","\n","        print(\n","            f\"Epoch {epoch+1}/{num_epochs} | \"\n","            f\"Train Loss: {train_loss:.4f} (Acc: {train_acc:.4f}, AUC: {train_auc:.4f}) | \"\n","            f\"Val Loss: {val_loss:.4f} (Acc: {val_acc:.4f}, AUC: {val_auc:.4f}) | \"\n","            f\"Val Sens: {val_sens:.4f} | Val Spec: {val_spec:.4f}\"\n","        )\n","\n","        early_stopper(val_auc, model)\n","        if early_stopper.early_stop:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","    print(f\"\\nBest validation AUC: {early_stopper.best_score:.4f}\")\n","    model.load_state_dict(early_stopper.best_model_wts)\n","    if ckpt_path:\n","        torch.save(model.state_dict(), ckpt_path)\n","        print(f\"Best model saved to {ckpt_path}\")\n","    if hist_path:\n","        with open(hist_path, 'wb') as f:\n","            pickle.dump(history, f)\n","        print(f\"Training history saved to {hist_path}\")\n","\n","    return model, history\n","\n","print(\"Starting the patient-level multi-task training...\")\n","\n","trained_model, training_history = run_training(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    device=device,\n","    num_epochs=30,\n","    lr=1e-4,\n","    seg_weight=1.0,\n","    patience=7,\n","    ckpt_path='/content/drive/MyDrive/MSc_project/best_patient_model_mtl.pth',\n","    hist_path='/content/drive/MyDrive/MSc_project/training_history.pkl'  # Training history is saved here\n",")\n","\n","print(\"\\nPatient-level multi-task training completed.\")"],"metadata":{"id":"OXtP-44EehDM"},"execution_count":null,"outputs":[]}]}